# -*- coding: utf-8 -*-
"""
Script para extraer datos de TRACK ID y generar CSV
Actualizado: 27 de abril de 2025
"""
# ------ Librerías -----
import os
import csv
from datetime import datetime

from bs4 import BeautifulSoup


import time

# ------------ Funciones ------------
def Get_Body_content(path: str, path_list:list, file: str) -> list:
    data = []

    with open(os.path.join(path, file), 'r', encoding='utf-8') as f:
        body = BeautifulSoup(f, 'html.parser')

    # Extraer System Time 
    System_Time = body.get_text().split("System Time:")[1].split("NIO")[0].strip("\n").split(" ")   # Filtra el texto para obtener solo el System Time, lo guarda en una lista separada por espacios
    System_Time = " ".join(System_Time[:-1])                                                        # Une el texto de la lista por espacios, eliminando el ultimo elemento que es el UTC
    System_Time = datetime.strptime(System_Time, ' %a, %d %b %Y %I:%M%p')                

    # Extraer fecha
    fecha = datetime.strptime(f"{path_list[0]}/{path_list[1]}/{path_list[2]}", '%Y/%B/%d')

    for Track_ID in body.find_all("h2"):
        temporal_dict = {}

        temporal_dict.update({"fecha":fecha})
        temporal_dict.update({"system time":System_Time})
        temporal_dict.update({"track id":int(Track_ID.contents[0].split(":")[1].strip())})
        temporal_dict.update({"subid":int(file.split("_")[1].split(".")[0])})
        temporal_dict.update({"path": path})
        temporal_dict.update({"# of images": 0})

        for tag in Track_ID.find_next_siblings():
            if tag.name == "label" and tag.next_sibling.strip() != "":
                temporal_dict.update({tag.contents[0].replace(":",""): tag.next_sibling.strip()})
                print(f"{tag.contents[0].replace(":","")}: {tag.next_sibling.strip()}")
            elif tag.name == "h2":
                break
        
        data.append(temporal_dict)

    return data

# -----------------------------------

if __name__ == "__main__":

    # ------ Variables ------
    # Rutas de las carpetas donde estan los archivos a procesar y donde se guardara el CSV
    base_path = "..\\Correos\\"    
    Indexed_Data_base = {}
    header = []

    images_len = 0

    for path, dir, files in os.walk(base_path):
        for file in files:

            # Divide el path en partes, obteniendo el nombre de la ruta separada.
            path_list = path.split(base_path)[1].split("\\")
            
            # print(f"{path}\\{file}")
            if len(path_list) == 4:     # Body
                
                Body_Data = Get_Body_content(path, path_list, file)
                
                for element in Body_Data:

                    if element["track id"] not in Indexed_Data_base:
                        Indexed_Data_base[element["track id"]] = {}
                    
                    while element["subid"] in Indexed_Data_base[element["track id"]]:
                        element["subid"] += 1

                    Indexed_Data_base[element["track id"]][element["subid"]] = element


            if len(path_list) == 5:     # Images
                images_len+=1
                Ruta = os.path.dirname(path)
                Track_ID = file.split("_")[1].split("-")[0]
                subid = path.split("\\")[-1].split("_")[1]

                if Track_ID.isdigit() and int(Track_ID) in Indexed_Data_base and int(subid) in Indexed_Data_base[int(Track_ID)]:
                    Track_ID = int(Track_ID)
                    subid = int(subid)
                    
                    if Indexed_Data_base[Track_ID][subid]["path"] == Ruta:
                        Indexed_Data_base[Track_ID][subid]["# of images"]+=1
                    else:
                        for element in Indexed_Data_base[Track_ID]:
                            if Indexed_Data_base[Track_ID][element]["path"] == Ruta:
                                Indexed_Data_base[Track_ID][element]["# of images"]+=1
                                break
                
    for TrackID in Indexed_Data_base:
        for SubId in Indexed_Data_base[TrackID]:
            header = Indexed_Data_base[TrackID][SubId].keys()
            break
        break

    with open(f"..\\Registros.csv", 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(header)

        for TrackID in Indexed_Data_base:
            for SubId in Indexed_Data_base[TrackID]:
                writer.writerow(Indexed_Data_base[TrackID][SubId].values())

    print(f"✅ Archivo CSV generado correctamente en: ..\\Registros.csv")
